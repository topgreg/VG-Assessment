{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4102f31",
   "metadata": {},
   "source": [
    "# VG - Assessment - Welliver\n",
    "\n",
    "Greg Welliver   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba529c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages.\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.ticker as plticker\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, preprocessing \n",
    "import warnings\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import linear_model, preprocessing, tree, svm, datasets, metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score, f1_score, log_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_tweedie_deviance, make_scorer\n",
    "\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from datetime import datetime, timedelta, date\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "from io import StringIO  \n",
    "import pydotplus\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_context('notebook')\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#sns.set_style(\"white\")\n",
    "style_set = sns.set_style('whitegrid')\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "color_choice1 = 'plum'\n",
    "color_choice2 = 'lightblue'\n",
    "color_choice3 = 'lightgreen'\n",
    "color_choice4 = 'blue'\n",
    "#ax.yaxis.set_major_formatter('{x:,.0f}')\n",
    "#sns.set_context('notebook', font_scale = 4)\n",
    "\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import contextily as ctx\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from ydata_profiling import ProfileReport\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf95157",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "dfe = pd.read_csv(\"email.csv\")\n",
    "dfd = pd.read_csv(\"demos.csv\")\n",
    "\n",
    "# X = pd.concat([X_train, X_test])\n",
    "# y = pd.concat([y_train, y_test])\n",
    "\n",
    "# eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "#df = pd.read_parquet(\"../Data/all_storm_data11.pqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2060715",
   "metadata": {},
   "source": [
    "First I'll look at the email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "dfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that aren't duplicate IDs\n",
    "dfe.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc374348",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7279c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a5385",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- It appears that when an event occurred (e.g. click_dt), the date is populated in the relevant column.  In the case of the bounced emails, it apperas a time is also tracked. Otherwise, if an event never occurs for a participant, the column shows as null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ee7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda functions to create columns for email analytics\n",
    "dfe['clicked_email'] = dfe['click_dt'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "dfe['bounced_email'] = dfe['bounce_dt'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "dfe['opened_email'] = dfe['open_dt'].apply(lambda x: 1 if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346be85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f7e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e7fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c4d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecaf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90c372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a8195a",
   "metadata": {},
   "source": [
    "Now I'll look at the demos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0814fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "dfd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that aren't duplicate IDs\n",
    "dfd.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad698b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6517d0",
   "metadata": {},
   "source": [
    "# <font color='red'>re-run for final**</font>\n",
    "\n",
    "profile = ProfileReport(dfd)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ac9fd",
   "metadata": {},
   "source": [
    "##### Observations on dataset\n",
    "- No missing values nor duplicates\n",
    "- Appears to be high correlation between fund_ct and status, and call_ct and campaign.  Will investigate this and determine best path forward.\n",
    "- There were some outliers that may need to be addressed (e.g. in fund_ct, and logon_ct); will check to see if removing them imporves modeling\n",
    "- balance: there are three negative balances, which doesn't seem logical. Thsi could be a data issue, or an accounting nuance\n",
    "- generally the features were reasonably well distributed. Not perfectly normal, but not skewed in a way that is overly concerning.\n",
    "- tenure: generally shows a normal distribution, however there are some strange dips in certain tenure periods. could be caused by something like seasonal acquisition of participants?\n",
    "- age: there is a peak in participants at one particular age - will need to investigate\n",
    "- gender: one value is unknown - it may make sense to amend this to either male or female.  gender data is also highly imbalanced towards males.\n",
    "- status: should only be values for 0 and 1, but there are 11 values that are either 2 or 3.  will need to modify this.\n",
    "- campaign: In theory this variable should have been split into thirds - i.e. one-third received Email A, one-third received Email B, one-third did not receive the email.  Instead many more participants received Email B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d24eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c54d4d2",
   "metadata": {},
   "source": [
    "Before addressing the issues called out above, I will merge the the two files on part_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfd.merge(dfe[['click_dt', 'bounce_dt', 'open_dt', 'clicked_email', 'bounced_email', 'opened_email']], how = 'left',\n",
    "                left_on = 'part_id', right_on = dfe['part_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape to ensure merge went correctly\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab540bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df[['fund_ct', 'logon_ct', 'call_ct', 'balance', 'tenure', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a16994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a scatter matrix to check if variables are normally distributed, as well see if there is correlation between variables\n",
    "#scatter_matrix(df_numeric, figsize=(12,12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the accounts with the negative balances\n",
    "df[df['balance'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c8fce",
   "metadata": {},
   "source": [
    "Interestingly, these users do share a number of characteristics.  However, there isn't enough information here to tell us what to do with these negative values, so will leave them as is for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b372f6c",
   "metadata": {},
   "source": [
    "Now let's look at the age feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90adf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['age'], bins=30)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ca1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22422e83",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The age of partipants has two peaks of concentration - one just above 44, and another right below 46.  There isn't anything to indicate we need to take action on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85f903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78dcbb8d",
   "metadata": {},
   "source": [
    "Now let's look at the gender variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e07124",
   "metadata": {},
   "source": [
    "With approximately 3/4 of users being male (0), we can change the 2 to a male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'gender' : {2 : 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ff839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "154f0661",
   "metadata": {},
   "source": [
    "Now let's look at status, particularly the observations with values of 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['status'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['status'] > 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cec7df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['status'] == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60182dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['status'] == 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77732f4",
   "metadata": {},
   "source": [
    "There doesn't appear to be any strong evidence to assign the observations in question to be either 0 or 1, so I will make them zeroes, since that represents about two-thirds of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc12baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'status' : {2 : 0, 3 : 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de032cd0",
   "metadata": {},
   "source": [
    "Let's look at the tenure variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef61d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['tenure'], bins=30)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706489c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tenure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a645c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2201fdf1",
   "metadata": {},
   "source": [
    "As a sanity check on the data, I want to see if there is click data for participants that didn't receive emails.  In theory there shouldn't be any click data for participants that didn't get emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87112a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['campaign'] == 2].clicked_email.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b207f",
   "metadata": {},
   "source": [
    "It looks like there are 1,119 participants that did not receive any emails (in campaign group 2), but are showing that they clicked the email.  I'll remove those observations since this is likely an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e886f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['campaign'] == 2].opened_email.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417d2b7",
   "metadata": {},
   "source": [
    "It looks like there are 2,213 participants that did not receive any emails (in campaign group 2), but are showing that they clicked the email.  I'll remove those observations since this is likely an error. Note that some of these likely overlap with the above clicked_email group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070adb3",
   "metadata": {},
   "source": [
    "Additionally, I want to check if there are observations that show click data, but the user never opened the email.  This should also in theory not be possible.  Based on the below, there are two such observations.  We will also delete these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.loc[(df['opened_email'] == 0) & (df['clicked_email'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2915e",
   "metadata": {},
   "source": [
    "I'll now take the steps to remove these three cases from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7230cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to delete observations where campaign == 2 and and clicked_email or open_email = 1\n",
    "#df.loc[(df['campaign'] == 2) & (df['clicked_email'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29076469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations where campaign == 2 and and clicked_email = 1\n",
    "df = df[ ~((df['campaign'] == 2) & (df['clicked_email'] == 1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63570e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify this worked correctly\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d75442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations where campaign == 2 and and opened_email = 1\n",
    "df = df[ ~((df['campaign'] == 2) & (df['opened_email'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that this worked correctly\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations where opened_email == 0 and and clicked_email = 1\n",
    "df = df[ ~((df['opened_email'] == 0) & (df['clicked_email'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2cbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18558e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1dea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noemail = df[df['campaign'] == 2]\n",
    "df_noemail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d893e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfe[dfe['part_id'] == 37299]\n",
    "dfe.loc[41763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aba8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.call_ct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd1e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ce62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf10e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ee5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.hist(figsize=(15,10))\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c9479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193a141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_numeric.corr()\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "hm = sns.heatmap(round(corrmat,2), annot=True, ax=ax, cmap='magma',fmt='.2f',\n",
    "                 linewidths=.05)\n",
    "\n",
    "f.subplots_adjust(top=0.93)\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dea1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fddf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbd735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dab0051c",
   "metadata": {},
   "source": [
    "# <font color='orange'>Modeling</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df = df.drop(['part_id', 'click_dt', 'bounce_dt', 'open_dt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7071fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab079d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb980f39",
   "metadata": {},
   "source": [
    "## Create dummy variables for categorical data types\n",
    "\n",
    "# isolate categorical variables\n",
    "categorical_features = df.select_dtypes(include=['object'])\n",
    "\n",
    "df = pd.concat([df.drop(categorical_features, axis=1), pd.get_dummies(categorical_features)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Split data into training and testing subsets\n",
    "\n",
    "# Create the X and y matrices from the dataframe\n",
    "X = df.drop(columns = ['clicked_email'])\n",
    "y = df['clicked_email']\n",
    "\n",
    "# from sklearn.model_selection import train_test_split; reserve 20% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=1234)\n",
    "\n",
    "#X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f41bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7953c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319ba25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ea1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc28e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b017e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2c6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9f246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe3fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6a5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc166610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc008f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e6610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb73c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e32247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a6310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b63f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6cd71c7",
   "metadata": {},
   "source": [
    "# <font color='orange'>Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 23)\n",
    "lr_clf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, lr_clf.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, lr_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10dd9f",
   "metadata": {},
   "source": [
    "#### Let's also look at a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd67062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = lr_clf.classes_)\n",
    "_, ax = plt.subplots()\n",
    "display_cm = ConfusionMatrixDisplay(confusion_matrix = cm, \n",
    "                                    display_labels = ['0', '1'])\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(labels = ['0', '1'], fontsize = 12)\n",
    "ax.set_yticklabels(labels = ['0', '1'], fontsize = 12)\n",
    "plt.grid(False)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "display_cm.plot(ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b846cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534e8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2fc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7949cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195692c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d07e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7121b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af4b85f",
   "metadata": {},
   "source": [
    "# <font color='orange'>Random Forest Model</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e23ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 3 estimators\n",
    "rf_clf = RandomForestClassifier(random_state = 123, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# let's look at classification report\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, rf_clf.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e522ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf_clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2999b",
   "metadata": {},
   "source": [
    "#### Now hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#markdown since it takes so long to run\n",
    "# %%time\n",
    "# rscv_rf = RandomizedSearchCV(RandomForestRegressor(random_state=1234),\n",
    "#                                    param_grid, n_jobs=-1)\n",
    "# rscv_rf.fit(X_train, y_train.values.ravel())\n",
    "# print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_cv = RandomForestRegressor(max_depth=6, max_features=None, min_samples_leaf=10,\n",
    "                      n_estimators=150, random_state=1234, n_jobs=-1, criterion='squared_error')\n",
    "rf_reg_cv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = rf_reg_cv.predict(X_train)\n",
    "#y_pred = rscv_rf.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = rf_reg_cv.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08808c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf_reg_cv.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057658e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(random_state=1234, metric='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd2a23",
   "metadata": {},
   "source": [
    "# <font color='orange'>Light GBM</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 3 estimators\n",
    "lgbm = LGBMClassifier(random_state = 123, n_jobs=-1)\n",
    "#lgbm.fit(X_train, y_train, early_stopping_rounds=20, eval_set=eval_set)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "# let's look at classification report\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, rf_clf.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7201c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lgbm.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ddc250",
   "metadata": {},
   "source": [
    "With this baseline, let's see how we can improve with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c31148",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'num_leaves': [10, 30, 50],\n",
    "    'colsample_bytree': [.3, .5, .8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81554c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# markdown since it takes so long to run\n",
    "# rscv_lgbm = RandomizedSearchCV(LGBMRegressor(random_state=1234),\n",
    "#                                    param_grid, n_jobs=-1)\n",
    "# rscv_lgbm.fit(X_train, y_train.values.ravel())\n",
    "# print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea02781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model with hyperparamters from random search\n",
    "lgbm_cv = LGBMRegressor(colsample_bytree=0.5, max_depth=9, n_estimators=150,\n",
    "              num_leaves=30, random_state=1234, metric='rmse')\n",
    "lgbm_cv.fit(X_train, y_train, early_stopping_rounds=20, eval_set=eval_set)\n",
    "\n",
    "y_pred = lgbm_cv.predict(X_train)\n",
    "#y_pred = rscv_lgbm.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = lgbm.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080482",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lgbm_cv.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fdd9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e84952ce",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82914f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cross-validation method to use\n",
    "cv = KFold(n_splits=10, random_state=1234, shuffle=True)\n",
    "\n",
    "#build multiple linear regression model\n",
    "#model = LGBMRegressor(random_state=1234)\n",
    "model = LGBMRegressor(random_state=1234)\n",
    "\n",
    "\n",
    "#use k-fold CV to evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view mean absolute error\n",
    "print(f\"{mean(abs(scores)):,.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd23e08",
   "metadata": {},
   "source": [
    "first run: \n",
    "\n",
    "model = LGBMRegressor(colsample_bytree=0.5, max_depth=9, n_estimators=150,\n",
    "              num_leaves=30, random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "RMSE: 131,769.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577836ce",
   "metadata": {},
   "source": [
    "second model: \n",
    "\n",
    "model = LGBMRegressor(random_state=1234)\n",
    "\n",
    "\n",
    "RMSE: 131,653.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5991c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679df4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c7635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a026d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05898d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eef10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c445705",
   "metadata": {},
   "source": [
    "# <font color='orange'>XGBoost</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "xgbr = XGBRegressor(random_state=1234, early_stopping_rounds=20, eval_metric='rmse')\n",
    "xgbr.fit(X_train, y_train, eval_set=eval_set)\n",
    "\n",
    "y_pred = xgbr.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = xgbr.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f143be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = xgbr.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'colsample_bytree': [.3, .5, .8],\n",
    "    'subsample': [.3, .5, .8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# markdown since it takes so long to run\n",
    "# rscv_xgb = RandomizedSearchCV(XGBRegressor(random_state=1234),\n",
    "#                                    param_grid, n_jobs=-1)\n",
    "# rscv_xgb.fit(X_train, y_train.values.ravel(), eval_set=eval_set)\n",
    "# print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af468f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "xgbr_cv = XGBRegressor(random_state=1234, eval_metric='rmse',\n",
    "                       learning_rate=0.1, \n",
    "                       max_depth=6, \n",
    "                       n_estimators=150,\n",
    "                       colsample_bytree=.8,\n",
    "                       subsample=.8)\n",
    "xgbr_cv.fit(X_train, y_train, eval_set=eval_set)\n",
    "\n",
    "y_pred = xgbr_cv.predict(X_train)\n",
    "#y_pred = rscv_xgb.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = xgbr_cv.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b525966",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = xgbr_cv.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:20]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color = 'plum')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc6c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2d0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f7f45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca129b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2457b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121a483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8418744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fbd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c70009",
   "metadata": {},
   "source": [
    "# <font color='orange'>Tweedie Regression</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f33d4b",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Filter out claims with zero amount, as the severity model requires strictly positive target values.\n",
    "- Correct for unreasonable observations (that might be data error) and a few exceptionally large claim amounts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - this dataset has the zeroes eliminated\n",
    "### comment out since current run doesn't contain any zeroes nor outliers\n",
    "# X_train = pd.read_parquet(\"../Data/X_train_td.pqt\")\n",
    "# X_test = pd.read_parquet(\"../Data/X_test_td.pqt\")\n",
    "# y_train = pd.read_parquet(\"../Data/y_train_td.pqt\") \n",
    "# y_test = pd.read_parquet(\"../Data/y_test_td.pqt\")\n",
    "\n",
    "# X = pd.concat([X_train, X_test])\n",
    "# y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03906734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdrg = linear_model.TweedieRegressor(max_iter=500)\n",
    "tdrg = TweedieRegressor(max_iter=500)\n",
    "tdrg.fit(X_train, y_train.values.ravel())\n",
    "# make predictions for test data\n",
    "y_pred = tdrg.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = tdrg.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb14e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a37ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'power': [0, 1, 2, 3],\n",
    "    'max_iter': [50, 100, 150, 200, 250, 500, 1000, 1500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# markdown since it takes so long to run\n",
    "# random_search = RandomizedSearchCV(linear_model.TweedieRegressor(),\n",
    "#                                    param_grid, n_jobs=-1)\n",
    "# random_search.fit(X_train, y_train.values.ravel())\n",
    "# print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tdrg_cv = TweedieRegressor(link='log', power=3, max_iter=50)\n",
    "# tdrg = linear_model.TweedieRegressor(max_iter=500)\n",
    "tdrg_cv = TweedieRegressor(link='log', power=1, max_iter=50)\n",
    "tdrg_cv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = tdrg_cv.predict(X_train)\n",
    "print('TRAIN:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_train, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_train, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_train, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_train, y_pred):,.1f}\")\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "y_pred = tdrg_cv.predict(X_test)\n",
    "print('TEST:')\n",
    "print('MAE: ', f\"{mean_absolute_error(y_test, y_pred):,.1f}\")\n",
    "print('MSE: ', f\"{mean_squared_error(y_test, y_pred):,.1f}\")\n",
    "print('RMSE:', f\"{np.sqrt(mean_squared_error(y_test, y_pred)):,.1f}\")\n",
    "print('MAPE: ', f\"{mean_absolute_percentage_error(y_test, y_pred):,.1f}\")\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\")\n",
    "print('MAE DIFF:', f\"{((test_mae / train_mae) - 1):.0%}\")\n",
    "print('RMSE DIFF:', f\"{((test_rmse / train_rmse) - 1):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b4228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'blue', alpha=0.2)\n",
    "plt.title('Actual Versus Predicted Values')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prredicted')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6135cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16ced0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0dedd34",
   "metadata": {},
   "source": [
    "SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the fifth model\n",
    "# model_mlr = sm.OLS(y_train, X_train)\n",
    "\n",
    "# # Fit the model\n",
    "# model_mlr_result = model_mlr.fit()\n",
    "\n",
    "# # Evaluate the model\n",
    "# model_mlr_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df = pd.DataFrame(data) \n",
    "\n",
    "# x = X\n",
    "# y = y\n",
    "\n",
    "# x = sm.add_constant(x)\n",
    "\n",
    "# model = sm.OLS(y, x).fit()\n",
    "# predictions = model.predict(x) \n",
    "\n",
    "# print_model = model.summary()\n",
    "# print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b2fc8",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/37144913/getting-valueerror-the-indices-for-endog-and-exog-are-not-aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
